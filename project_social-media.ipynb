{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project - Social Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUSINESS CHALLENGE/REQUIREMENT:\n",
    "\n",
    "Congratulations!! for making it so far. You now have a full fledge project to apply Machine Learning skills you have learned till Module 11.\n",
    "Mashable (www.mashable.com) -- is a global, multi-platform media and entertainment company. Powered by its own proprietary technology, Mashable is the go-to source for tech, digital culture and entertainment content for its dedicated and influential audience around the globe.\n",
    "Just like any other media company its success depends on the popularity of articles. And one of the key metrics to measure popularity is no. of shares done on article.\n",
    "Over period of few years Mashable has collected data on around 40,000 articles.\n",
    "You as ML expert have to do analysis and modeling to predict number of shares of an article given the input parameters.\n",
    "\n",
    "KEY ISSUES:\n",
    "\n",
    "• Data contains large number of features\n",
    "• Prediction is of continuous value (shares)\n",
    "\n",
    "DATA VOLUME:\n",
    "\n",
    "- 39797 records – file - OnlineNewsPopularity.csv\n",
    "\n",
    "Fields in Data:\n",
    "\n",
    "• Details in Module-12-Project-Popularity-Analysis.ipynb notebook\n",
    "\n",
    "BUSINESS BENEFITS:\n",
    "\n",
    "Mashable’s entire business is dependent on popularity of articles. With accurate prediction of shares, company can choose which articles to publish hence driving higher user engagement and profits. Rough estimate is 1% increase in engagement time (minutes) increases profit by up to 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreeraj.va\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\E\\Courses\\Edureka\\Assignments\\Dataset\\Projects\\OnlineNewsPopularity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39644, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0            12.0             219.0         0.663594               1.0   \n",
       "1             9.0             255.0         0.604743               1.0   \n",
       "2             9.0             211.0         0.575130               1.0   \n",
       "3             9.0             531.0         0.503788               1.0   \n",
       "4            13.0            1072.0         0.415646               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.815385        4.0             2.0       1.0  ...   \n",
       "1                  0.791946        3.0             1.0       1.0  ...   \n",
       "2                  0.663866        3.0             1.0       1.0  ...   \n",
       "3                  0.665635        9.0             0.0       1.0  ...   \n",
       "4                  0.540890       19.0            19.0      20.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.100000                    0.7              -0.350000   \n",
       "1               0.033333                    0.7              -0.118750   \n",
       "2               0.100000                    1.0              -0.466667   \n",
       "3               0.136364                    0.8              -0.369697   \n",
       "4               0.033333                    1.0              -0.220192   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                 -0.600              -0.200000            0.500000   \n",
       "1                 -0.125              -0.100000            0.000000   \n",
       "2                 -0.800              -0.133333            0.000000   \n",
       "3                 -0.600              -0.166667            0.000000   \n",
       "4                 -0.500              -0.050000            0.454545   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                 -0.187500                0.000000   \n",
       "1                  0.000000                0.500000   \n",
       "2                  0.000000                0.500000   \n",
       "3                  0.000000                0.500000   \n",
       "4                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  \n",
       "0                      0.187500     593  \n",
       "1                      0.000000     711  \n",
       "2                      0.000000    1500  \n",
       "3                      0.000000    1200  \n",
       "4                      0.136364     505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>354.530471</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>0.689175</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>4.544143</td>\n",
       "      <td>1.249874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>3395.380184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>214.163767</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>3.520708</td>\n",
       "      <td>5.231231</td>\n",
       "      <td>3.264816</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>8.309434</td>\n",
       "      <td>4.107855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>11626.950749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>339.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>0.539226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>542.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  39644.000000    39644.000000      39644.000000     39644.000000   \n",
       "mean     354.530471       10.398749        546.514731         0.548216   \n",
       "std      214.163767        2.114037        471.107508         3.520708   \n",
       "min        8.000000        2.000000          0.000000         0.000000   \n",
       "25%      164.000000        9.000000        246.000000         0.470870   \n",
       "50%      339.000000       10.000000        409.000000         0.539226   \n",
       "75%      542.000000       12.000000        716.000000         0.608696   \n",
       "max      731.000000       23.000000       8474.000000       701.000000   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count      39644.000000              39644.000000  39644.000000   \n",
       "mean           0.996469                  0.689175     10.883690   \n",
       "std            5.231231                  3.264816     11.332017   \n",
       "min            0.000000                  0.000000      0.000000   \n",
       "25%            1.000000                  0.625739      4.000000   \n",
       "50%            1.000000                  0.690476      8.000000   \n",
       "75%            1.000000                  0.754630     14.000000   \n",
       "max         1042.000000                650.000000    304.000000   \n",
       "\n",
       "       num_self_hrefs      num_imgs    num_videos  ...  min_positive_polarity  \\\n",
       "count    39644.000000  39644.000000  39644.000000  ...           39644.000000   \n",
       "mean         3.293638      4.544143      1.249874  ...               0.095446   \n",
       "std          3.855141      8.309434      4.107855  ...               0.071315   \n",
       "min          0.000000      0.000000      0.000000  ...               0.000000   \n",
       "25%          1.000000      1.000000      0.000000  ...               0.050000   \n",
       "50%          3.000000      1.000000      0.000000  ...               0.100000   \n",
       "75%          4.000000      4.000000      1.000000  ...               0.100000   \n",
       "max        116.000000    128.000000     91.000000  ...               1.000000   \n",
       "\n",
       "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean                0.756728              -0.259524              -0.521944   \n",
       "std                 0.247786               0.127726               0.290290   \n",
       "min                 0.000000              -1.000000              -1.000000   \n",
       "25%                 0.600000              -0.328383              -0.700000   \n",
       "50%                 0.800000              -0.253333              -0.500000   \n",
       "75%                 1.000000              -0.186905              -0.300000   \n",
       "max                 1.000000               0.000000               0.000000   \n",
       "\n",
       "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "count           39644.000000        39644.000000              39644.000000   \n",
       "mean               -0.107500            0.282353                  0.071425   \n",
       "std                 0.095373            0.324247                  0.265450   \n",
       "min                -1.000000            0.000000                 -1.000000   \n",
       "25%                -0.125000            0.000000                  0.000000   \n",
       "50%                -0.100000            0.150000                  0.000000   \n",
       "75%                -0.050000            0.500000                  0.150000   \n",
       "max                 0.000000            1.000000                  1.000000   \n",
       "\n",
       "       abs_title_subjectivity  abs_title_sentiment_polarity         shares  \n",
       "count            39644.000000                  39644.000000   39644.000000  \n",
       "mean                 0.341843                      0.156064    3395.380184  \n",
       "std                  0.188791                      0.226294   11626.950749  \n",
       "min                  0.000000                      0.000000       1.000000  \n",
       "25%                  0.166667                      0.000000     946.000000  \n",
       "50%                  0.500000                      0.000000    1400.000000  \n",
       "75%                  0.500000                      0.250000    2800.000000  \n",
       "max                  0.500000                      1.000000  843300.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39644 entries, 0 to 39643\n",
      "Data columns (total 61 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   url                             39644 non-null  object \n",
      " 1   timedelta                       39644 non-null  float64\n",
      " 2   n_tokens_title                  39644 non-null  float64\n",
      " 3   n_tokens_content                39644 non-null  float64\n",
      " 4   n_unique_tokens                 39644 non-null  float64\n",
      " 5   n_non_stop_words                39644 non-null  float64\n",
      " 6   n_non_stop_unique_tokens        39644 non-null  float64\n",
      " 7   num_hrefs                       39644 non-null  float64\n",
      " 8   num_self_hrefs                  39644 non-null  float64\n",
      " 9   num_imgs                        39644 non-null  float64\n",
      " 10  num_videos                      39644 non-null  float64\n",
      " 11  average_token_length            39644 non-null  float64\n",
      " 12  num_keywords                    39644 non-null  float64\n",
      " 13  data_channel_is_lifestyle       39644 non-null  float64\n",
      " 14   data_channel_is_entertainment  39644 non-null  float64\n",
      " 15  data_channel_is_bus             39644 non-null  float64\n",
      " 16  data_channel_is_socmed          39644 non-null  float64\n",
      " 17  data_channel_is_tech            39644 non-null  float64\n",
      " 18  data_channel_is_world           39644 non-null  float64\n",
      " 19  kw_min_min                      39644 non-null  float64\n",
      " 20  kw_max_min                      39644 non-null  float64\n",
      " 21  kw_avg_min                      39644 non-null  float64\n",
      " 22  kw_min_max                      39644 non-null  float64\n",
      " 23  kw_max_max                      39644 non-null  float64\n",
      " 24  kw_avg_max                      39644 non-null  float64\n",
      " 25  kw_min_avg                      39644 non-null  float64\n",
      " 26  kw_max_avg                      39644 non-null  float64\n",
      " 27  kw_avg_avg                      39644 non-null  float64\n",
      " 28  self_reference_min_shares       39644 non-null  float64\n",
      " 29  self_reference_max_shares       39644 non-null  float64\n",
      " 30  self_reference_avg_sharess      39644 non-null  float64\n",
      " 31  weekday_is_monday               39644 non-null  float64\n",
      " 32  weekday_is_tuesday              39644 non-null  float64\n",
      " 33  weekday_is_wednesday            39644 non-null  float64\n",
      " 34  weekday_is_thursday             39644 non-null  float64\n",
      " 35  weekday_is_friday               39644 non-null  float64\n",
      " 36  weekday_is_saturday             39644 non-null  float64\n",
      " 37  weekday_is_sunday               39644 non-null  float64\n",
      " 38  is_weekend                      39644 non-null  float64\n",
      " 39  LDA_00                          39644 non-null  float64\n",
      " 40  LDA_01                          39644 non-null  float64\n",
      " 41  LDA_02                          39644 non-null  float64\n",
      " 42  LDA_03                          39644 non-null  float64\n",
      " 43  LDA_04                          39644 non-null  float64\n",
      " 44  global_subjectivity             39644 non-null  float64\n",
      " 45  global_sentiment_polarity       39644 non-null  float64\n",
      " 46  global_rate_positive_words      39644 non-null  float64\n",
      " 47  global_rate_negative_words      39644 non-null  float64\n",
      " 48  rate_positive_words             39644 non-null  float64\n",
      " 49  rate_negative_words             39644 non-null  float64\n",
      " 50  avg_positive_polarity           39644 non-null  float64\n",
      " 51  min_positive_polarity           39644 non-null  float64\n",
      " 52  max_positive_polarity           39644 non-null  float64\n",
      " 53  avg_negative_polarity           39644 non-null  float64\n",
      " 54  min_negative_polarity           39644 non-null  float64\n",
      " 55  max_negative_polarity           39644 non-null  float64\n",
      " 56  title_subjectivity              39644 non-null  float64\n",
      " 57  title_sentiment_polarity        39644 non-null  float64\n",
      " 58  abs_title_subjectivity          39644 non-null  float64\n",
      " 59  abs_title_sentiment_polarity    39644 non-null  float64\n",
      " 60  shares                          39644 non-null  int64  \n",
      "dtypes: float64(59), int64(1), object(1)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_df = pd.DataFrame(df.isna().sum())\n",
    "max(list(na_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,1:60].values\n",
    "y = df.iloc[:,60].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31715, 7929, 31715, 7929)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying with Leniar regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5439087570482766"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13914.107810473733"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(y_test, y_pred_lr))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shares</th>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.045404</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.039388</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00004</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>-0.032029</td>\n",
       "      <td>-0.019297</td>\n",
       "      <td>-0.0193</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.027135</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "shares   0.008662        0.008783          0.002459         0.000806   \n",
       "\n",
       "        n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "shares          0.000443                  0.000114   0.045404         -0.0019   \n",
       "\n",
       "        num_imgs  num_videos  ...  min_positive_polarity  \\\n",
       "shares  0.039388    0.023936  ...               -0.00004   \n",
       "\n",
       "        max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "shares               0.010068              -0.032029              -0.019297   \n",
       "\n",
       "        max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "shares                -0.0193            0.021967                  0.012772   \n",
       "\n",
       "        abs_title_subjectivity  abs_title_sentiment_polarity  shares  \n",
       "shares                0.001481                      0.027135     1.0  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1:].corr(method ='pearson').iloc[-1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1:].corr(method ='pearson').iloc[-1:,:].to_csv(r'C:\\Users\\sreeraj.va\\Documents\\corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new x only with independant variables having comparatively higher correlation.\n",
    "\n",
    "x2 =df[['kw_avg_avg', 'LDA_03', 'kw_max_avg', 'self_reference_avg_sharess', 'self_reference_min_shares', 'self_reference_max_shares', 'num_hrefs', 'kw_avg_max', 'kw_min_avg', 'num_imgs', 'global_subjectivity', 'kw_avg_min', 'kw_max_min', 'abs_title_sentiment_polarity', 'num_videos', 'title_subjectivity', 'num_keywords', 'is_weekend', 'weekday_is_saturday', 'title_sentiment_polarity', 'avg_positive_polarity', 'max_positive_polarity']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train, x2_test, y_train, y_test = train_test_split(x2,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31715, 7929, 31715, 7929)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x2_train), len(x2_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model2 = LinearRegression()\n",
    "lr_model2.fit(x2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = lr_model2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02141799587305615"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### r2_score of the second model (lr_model2) is better than first one.\n",
    "\n",
    "still we will go with decesion tree and rendom forest. Then we will fix one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14206.9920066062"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "(mean_squared_error(y_test, y_pred_dt))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE looks OK for decesion tree model with all independant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking decision tree with higher correlation variables\n",
    "\n",
    "dt_model2 = DecisionTreeRegressor()\n",
    "dt_model2.fit(x2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt2 = dt_model2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12283.670807211374"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(y_test, y_pred_dt2))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RMSE reduced for decesion tree moel more correlated independant variables.\n",
    "\n",
    "Still we will try with random forest also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9672.881610973625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(y_test, y_pred_rf))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying gridsearchcv and checking best value for n_estimators\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lst = list(range(1,51))\n",
    "\n",
    "parameters = [{'n_estimators' : lst}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreeraj.va\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=parameters, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search = grid_search.fit(x_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-163047304.75428227"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 49}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=49, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating random forest model with 49 trees\n",
    "\n",
    "rf_model2 = RandomForestRegressor(n_estimators=49)\n",
    "rf_model2.fit(x_train, y_train)# creating random forest model with 49 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf2 = rf_model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9323.201190425427"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(y_test, y_pred_rf2))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=49, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating random forest model with high correlation independant variables only\n",
    "\n",
    "rf_model3 = RandomForestRegressor(n_estimators=49)\n",
    "rf_model3.fit(x2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf3 = rf_model3.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9131.153072862635"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(y_test, y_pred_rf3))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can go with Random forest regressor with high correlated independant variables only with n_estimator=49 (rf_model3) for the number of shares prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
